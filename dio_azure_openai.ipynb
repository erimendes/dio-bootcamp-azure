{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAYv9dtSX+7TkbOH0Cp3Va",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/erimendes/dio-bootcamp-azure/blob/main/dio_azure_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "1BlLJ76-K9-C",
        "outputId": "d8bca2de-82e9-4550-8418-995c69dab56d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"OpenAI o1 Capabilities - DEV Community\\nForem Feed\\nFollow new Subforems to improve your feed\\nDEV Community\\nFollow\\nA space to discuss and keep up software development and manage your software career\\nOpen Forem\\nFollow\\nA general discussion space for the Forem community. If it doesn't have a home elsewhere, it belongs here\\nFuture\\nFollow\\nNews and discussion of science and technology such as AI, VR, cryptocurrency, quantum computing, and more.\\nGamers Forem\\nFollow\\nAn inclusive community for gaming enthusiasts\\nMusic Forem\\nFollow\\nFrom composing and gigging to gear, hot music takes, and everything in between.\\nVibe Coding Forem\\nFollow\\nDiscussing AI software development, and showing off what we're building.\\nDUMB DEV Community\\nFollow\\nMemes and software development shitposting\\nPopcorn Movies and TV\\nFollow\\nMovie and TV enthusiasm, criticism and everything in-between.\\nDesign Community\\nFollow\\nWeb design, graphic design and everything in-between\\nSecurity Forem\\nFollow\\nYour central hub for all things security. From ethical hacking and CTFs to GRC and career development, for beginners and pros alike\\nGolf Forem\\nFollow\\nA community of golfers and golfing enthusiasts\\nCrypto Forem\\nFollow\\nA collaborative community for all things Crypto‚Äîfrom Bitcoin to protocol development and DeFi to NFTs and market analysis.\\nParenting\\nFollow\\nA place for parents to the share the joys, challenges, and wisdom that come from raising kids. We're here for them and for each other.\\nForem Core\\nFollow\\nDiscussing the core forem open source software project ‚Äî features, bugs, performance, self-hosting.\\nMaker Forem\\nFollow\\nA community for makers, hobbyists, and professionals to discuss Arduino, Raspberry Pi, 3D printing, and much more.\\nHMPL.js Forem\\nFollow\\nFor developers using HMPL.js to build fast, lightweight web apps. A space to share projects, ask questions, and discuss server-driven templating\\nDropdown menu\\nDropdown menu\\nSkip to content\\nNavigation menu\\nSearch\\nPowered by Algolia\\nSearch\\nLog in\\nCreate account\\nDEV Community\\nClose\\nAdd reaction\\nLike\\nUnicorn\\nExploding Head\\nRaised Hands\\nFire\\nJump to Comments\\nSave\\nBoost\\nMore...\\nCopy link\\nCopy link\\nCopied to Clipboard\\nShare to X\\nShare to LinkedIn\\nShare to Facebook\\nShare to Mastodon\\nReport Abuse\\nMaksim Tarasov\\nPosted on\\nFeb 14, 2025\\n‚Ä¢ Edited on\\nFeb 17, 2025\\nOpenAI o1 Capabilities\\n# ai\\n# openai\\nWhat is OpenAI o1?\\nOpenAI o1\\nis an advanced artificial intelligence model developed by OpenAI. This AI model leverages cutting-edge deep learning techniques to facilitate a range of tasks, from understanding and generating human-like text to more complex problem-solving scenarios. OpenAI o1 stands as a testament to the remarkable advancements in AI technology, offering improvements in accuracy, efficiency, and versatility over previous iterations.\\n\\u200d\\nSignificance in the AI Community\\nOpenAI o1\\nholds a prominent position in the AI community due to its robust capabilities and potential applications. Its significance is marked by its contributions to both academic research and commercial ventures. Researchers utilize OpenAI o1 to test new theories and enhance AI-related studies, while businesses leverage its capabilities to optimize operations, enhance customer service, and support decision-making processes.\\nOpenAI o1 is poised to continue shaping the future of artificial intelligence, contributing to a variety of fields and demonstrating the vast potentials of modern AI technology.\\n\\u200d\\nDeep Learning Capabilities\\nOpenAI o1 leverages sophisticated deep learning algorithms to process vast amounts of data. This model excels in recognizing intricate patterns and making accurate predictions. By using multiple layers of artificial neurons, OpenAI o1 can perform complex operations such as image recognition, speech identification, and more.\\nOne notable aspect of its deep learning potential is its ability to adapt and improve over time without explicit programming. This feature makes it exceptionally useful in environments where data and conditions continually evolve.\\n\\u200d\\nProcessing Speed\\nOpenAI o1 showcases impressive processing speed, making it a powerful tool for various AI applications. The model's architecture is designed to handle large volumes of data quickly and efficiently. The following table illustrates the processing speed of OpenAI o1 in different scenarios:\\nThese numbers are indicative of the model's ability to perform complex tasks in a relatively short amount of time. The high processing speed is one of the key attributes that set OpenAI o1 apart from other AI models.\\n\\u200d\\nScalability\\nScalability is another vital aspect of OpenAI o1. The model is designed to scale efficiently, allowing it to handle increasing workloads without a significant drop in performance. Scalability is crucial for applications that require processing large datasets or handling multiple simultaneous tasks.\\nThe table above demonstrates how OpenAI o1 maintains its efficiency even as the number of tasks increases. With minimal performance degradation, the model ensures consistent output quality, making it suitable for large-scale applications. For additional information on the scalability of OpenAI o1, visit our article on openai o1 technology.\\nBy optimizing both processing speed and scalability, OpenAI o1 stands out as a highly efficient model in the AI community. These attributes contribute to its wide range of potential applications, from enhancing chatbots to supporting data analysis.\\n\\u200d\\nOpen-Source Nature\\nOpenAI o1 exemplifies accessibility within the AI community through its open-source nature. By making its codebase freely available, OpenAI allows developers, researchers, and enthusiasts to explore, modify, and adapt the model to suit various applications. This democratization of AI technology ensures that innovations are not confined to a select few but can be widely distributed and applied.\\nOne of the key benefits of open-source AI models like OpenAI o1 is the ability to foster collaborative advancements. Developers from around the globe can contribute to the code, improving its functionality, performance, and addressing any issues that may arise. This collaborative effort accelerates the development process and leads to more robust AI systems.\\n\\u200d\\nAddressing Bias and Fairness\\nAI systems, including OpenAI o1, are trained on vast datasets. These datasets can inadvertently carry biases from the real world, which AI models might then perpetuate or even exacerbate.\\nBy adopting these strategies, OpenAI o1 aims to create more balanced AI outcomes, encouraging ethical use in applications such as openai o1 applications and enhancing chatbots.\\nTop comments\\n(0)\\nSubscribe\\nPersonal\\nTrusted User\\nCreate template\\nTemplates let you quickly answer FAQs or store snippets for re-use.\\nSubmit\\nPreview\\nDismiss\\nCode of Conduct\\n‚Ä¢\\nReport abuse\\nAre you sure you want to hide this comment? It will become hidden in your post, but will still be visible via the comment's\\npermalink .\\nHide child comments as well\\nConfirm\\nFor further actions, you may consider blocking this person and/or\\nreporting abuse\\nMaksim Tarasov\\nFollow\\nJoined\\nJan 9, 2025\\nMore from\\nMaksim Tarasov\\nThe Benefits of ChatGPT 4.5\\n# ai\\n# chatgpt\\nGPT 4.5 Overview\\n# ai\\n# chatgpt\\nExploring GPT 4.5 Features\\n# ai\\n# chatgpt\\nüíé DEV Diamond Sponsors\\nThank you to our Diamond Sponsors for supporting the DEV Community\\nGoogle AI is the official AI Model and Platform Partner of DEV\\nNeon is the official database partner of DEV\\nAlgolia is the official search partner of DEV\\nDEV Community\\n‚Äî A space to discuss and keep up software development and manage your software career\\nHome\\nReading List\\nAbout\\nContact\\nCode of Conduct\\nPrivacy Policy\\nTerms of Use\\nBuilt on\\nForem\\n‚Äî the\\nopen source\\nsoftware that powers\\nDEV\\nand other inclusive communities.\\nMade with love and\\nRuby on Rails . DEV Community\\n¬©\\n2016 - 2026.\\nWe're a place where coders share, stay up-to-date and grow their careers.\\nLog in\\nCreate account\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def extract_text_from_url(url):\n",
        "  response = requests.get(url)\n",
        "\n",
        "  if response.status_code == 200:\n",
        "    soup = BeautifulSoup(response.text, 'html.parser')\n",
        "    for script_or_style in soup(['script', 'style']):\n",
        "      script_or_style.decompose()\n",
        "    texto = soup.get_text(separator=' ')\n",
        "    # Limpar texto\n",
        "    lines = (line.strip() for line in texto.splitlines())\n",
        "    parts = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
        "    text_clear = '\\n'.join(part for part in parts if part)\n",
        "    return text_clear\n",
        "  else:\n",
        "    print(f\"Failed to fetch the URL. Status code: {response.status_code}\")\n",
        "    return None\n",
        "\n",
        "  text = soup.get_text()\n",
        "  return text\n",
        "\n",
        "extract_text_from_url('https://dev.to/maksim_tarasov_c60917a469/openai-o1-capabilities-1pga')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7w4ZdEeegVGE",
        "outputId": "f8a12943-d8c4-4077-a7e8-be0b7187651b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-groq\n",
            "  Downloading langchain_groq-1.1.1-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq)\n",
            "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-groq) (1.2.7)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (0.28.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (2.12.3)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.12/dist-packages (from groq<1.0.0,>=0.30.0->langchain-groq) (4.15.0)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.33)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.6.5)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (25.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (6.0.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (9.1.2)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.14.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.5.0->groq<1.0.0,>=0.30.0->langchain-groq) (3.11)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.0.0)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.11.5)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.32.4)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (0.25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=1.9.0->groq<1.0.0,>=0.30.0->langchain-groq) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.1.0->langchain-groq) (2.5.0)\n",
            "Downloading langchain_groq-1.1.1-py3-none-any.whl (19 kB)\n",
            "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: groq, langchain-groq\n",
            "Successfully installed groq-0.37.1 langchain-groq-1.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "import os\n",
        "\n",
        "# Configure sua chave de API (ou use vari√°veis de ambiente)\n",
        "os.environ[\"GROQ_API_KEY\"] = \"\"\n",
        "\n",
        "client = ChatGroq(\n",
        "    model=\"llama-3.3-70b-versatile\", # Ou outro modelo dispon√≠vel no Groq como 'mixtral-8x7b-32768'\n",
        "    temperature=0.5,\n",
        "    # api_key=\"CHAVE\" # Opcional se j√° estiver no environment\n",
        ")\n",
        "\n",
        "def translate_article(text, lang):\n",
        "    messages = [\n",
        "        (\"system\", \"Voc√™ atua como tradutor de textos\"),\n",
        "        (\"user\", f\"Traduza o texto abaixo para o idioma {lang} e responda estritamente em markdown.\\n\\nTexto: {text}\")\n",
        "    ]\n",
        "\n",
        "    response = client.invoke(messages)\n",
        "\n",
        "    # No LangChain, o conte√∫do principal da resposta fica em .content\n",
        "    return response.content\n",
        "\n",
        "# Teste\n",
        "resultado = translate_article(\"Let's see if the deployment was succeeded.\", \"portugu√™s\")\n",
        "print(resultado)\n"
      ],
      "metadata": {
        "id": "3KvJFqF6O6ug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34f0e144-0870-4aec-df5f-20c1b1e14d3e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Tradu√ß√£o do Texto\n",
            "Vamos ver se a implanta√ß√£o foi bem-sucedida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'\n",
        "text = extract_text_from_url(url)\n",
        "article = translate_article(text, \"pt-br\")\n",
        "print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miqX3EnBh_nr",
        "outputId": "59e1e7f8-b2f3-4dca-bd3c-fb309a0dec1b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Azure Open AI em VNet - Comunidade DEV\n",
            "A Comunidade DEV √© um espa√ßo para discutir e se manter atualizado sobre desenvolvimento de software e gerenciar sua carreira em software. Neste artigo, vamos explorar como usar o Azure Open AI em uma rede virtual (VNet) para melhorar a seguran√ßa.\n",
            "\n",
            "#### Introdu√ß√£o\n",
            "Os modelos GPT s√£o hospedados em v√°rios provedores de servi√ßos, incluindo a Microsoft Azure. Embora os modelos sejam os mesmos, h√° muitas diferen√ßas, incluindo custo, funcionalidades, tipo de modelos e vers√µes, localiza√ß√£o geogr√°fica, seguran√ßa, suporte, etc. Um dos aspectos mais importantes ao usar o Azure Open AI em um ambiente empresarial √© a seguran√ßa.\n",
            "\n",
            "#### Usando Azure Open AI em VNet\n",
            "Ao usar as funcionalidades de seguran√ßa de rede do Azure com o Azure Open AI, os clientes podem consumir o servi√ßo Open AI de dentro da VNet, sem que nenhuma informa√ß√£o flua em p√∫blico. O reposit√≥rio de amostras do Azure fornece um arquivo Bicep para implantar o Azure Open AI em um ambiente VNet.\n",
            "\n",
            "#### Recursos principais\n",
            "Os recursos principais usados pelo arquivo Bicep incluem:\n",
            "\n",
            "* VNet\n",
            "* Integra√ß√£o de VNet para aplicativos web\n",
            "* Ponto de extremidade privado para Azure Open AI\n",
            "* Ponto de extremidade privado para Cognitive Search\n",
            "* Zona DNS privada\n",
            "\n",
            "#### Implanta√ß√£o\n",
            "O arquivo Bicep implantar√° os seguintes recursos do Azure:\n",
            "\n",
            "* VNet\n",
            "* Aplicativo web\n",
            "* Ponto de extremidade privado para Azure Open AI\n",
            "* Ponto de extremidade privado para Cognitive Search\n",
            "* Zona DNS privada\n",
            "\n",
            "#### Teste\n",
            "Depois de implantar os recursos, podemos testar se a implanta√ß√£o foi bem-sucedida. Primeiro, tentamos acessar o Azure Open AI por meio do Chat Playground no Portal do Azure. Em seguida, tentamos acessar o servi√ßo por meio da API web.\n",
            "\n",
            "#### Conclus√£o\n",
            "Usar o Azure Open AI em uma VNet √© uma √≥tima maneira de melhorar a seguran√ßa ao consumir o servi√ßo. Com as funcionalidades de seguran√ßa de rede do Azure, podemos garantir que nenhuma informa√ß√£o flua em p√∫blico. Al√©m disso, o arquivo Bicep fornece uma maneira f√°cil de implantar o Azure Open AI em um ambiente VNet.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -q google-genai"
      ],
      "metadata": {
        "collapsed": true,
        "id": "CvWR_AB2l1dt"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "genai.configure(api_key=\"\")\n",
        "\n",
        "for m in genai.list_models():\n",
        "    if 'generateContent' in m.supported_generation_methods:\n",
        "        print(m.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "id": "87Ire-uxpWcr",
        "outputId": "171f56d4-e903-4c47-85e3-749b7c792d9b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "models/gemini-2.5-flash\n",
            "models/gemini-2.5-pro\n",
            "models/gemini-2.0-flash\n",
            "models/gemini-2.0-flash-001\n",
            "models/gemini-2.0-flash-exp-image-generation\n",
            "models/gemini-2.0-flash-lite-001\n",
            "models/gemini-2.0-flash-lite\n",
            "models/gemini-exp-1206\n",
            "models/gemini-2.5-flash-preview-tts\n",
            "models/gemini-2.5-pro-preview-tts\n",
            "models/gemma-3-1b-it\n",
            "models/gemma-3-4b-it\n",
            "models/gemma-3-12b-it\n",
            "models/gemma-3-27b-it\n",
            "models/gemma-3n-e4b-it\n",
            "models/gemma-3n-e2b-it\n",
            "models/gemini-flash-latest\n",
            "models/gemini-flash-lite-latest\n",
            "models/gemini-pro-latest\n",
            "models/gemini-2.5-flash-lite\n",
            "models/gemini-2.5-flash-image\n",
            "models/gemini-2.5-flash-preview-09-2025\n",
            "models/gemini-2.5-flash-lite-preview-09-2025\n",
            "models/gemini-3-pro-preview\n",
            "models/gemini-3-flash-preview\n",
            "models/gemini-3-pro-image-preview\n",
            "models/nano-banana-pro-preview\n",
            "models/gemini-robotics-er-1.5-preview\n",
            "models/gemini-2.5-computer-use-preview-10-2025\n",
            "models/deep-research-pro-preview-12-2025\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google import genai\n",
        "import os\n",
        "\n",
        "# Configure sua chave\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"\"\n",
        "\n",
        "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n",
        "def translate_article(text, lang):\n",
        "    try:\n",
        "        # O modelo 'gemini-1.5-flash' √© o padr√£o gratuito atual\n",
        "        response = client.models.generate_content(\n",
        "            model=\"gemini-2.5-flash\",\n",
        "            contents=f\"Voc√™ atua como tradutor. Traduza para {lang} em formato markdown: {text}\"\n",
        "        )\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao traduzir: {e}\"\n",
        "\n",
        "# Teste\n",
        "resultado = translate_article(\"Let's see if the deployment was succeeded.\", \"portugu√™s\")\n",
        "print(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDgc1mnrkSAA",
        "outputId": "2267f74f-4de3-483e-b1e5-ebedc19cb7c9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vamos ver se a implanta√ß√£o foi bem-sucedida.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "url = 'https://dev.to/kenakamu/azure-open-ai-in-vnet-3alo'\n",
        "text = extract_text_from_url(url)\n",
        "article = translate_article(text, \"pt-br\")\n",
        "print(article)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdssxkpMrk0O",
        "outputId": "1c92968f-6340-4c33-d1ce-94ed644881d1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```markdown\n",
            "# Azure Open AI em VNet - Comunidade DEV\n",
            "\n",
            "## Feed do Forem\n",
            "\n",
            "Siga novos Subforems para melhorar seu feed\n",
            "\n",
            "## Comunidade DEV\n",
            "\n",
            "Seguir\n",
            "\n",
            "Um espa√ßo para discutir e manter-se atualizado sobre desenvolvimento de software e gerenciar sua carreira em software\n",
            "\n",
            "## Forem Aberto\n",
            "\n",
            "Seguir\n",
            "\n",
            "Um espa√ßo de discuss√£o geral para a comunidade Forem. Se n√£o tiver um lar em outro lugar, pertence aqui\n",
            "\n",
            "## Futuro\n",
            "\n",
            "Seguir\n",
            "\n",
            "Not√≠cias e discuss√µes sobre ci√™ncia e tecnologia, como IA, RV, criptomoeda, computa√ß√£o qu√¢ntica e muito mais.\n",
            "\n",
            "## Forem de Jogadores\n",
            "\n",
            "Seguir\n",
            "\n",
            "Uma comunidade inclusiva para entusiastas de jogos\n",
            "\n",
            "## Forem de M√∫sica\n",
            "\n",
            "Seguir\n",
            "\n",
            "Desde compor e fazer shows at√© equipamentos, opini√µes musicais quentes e tudo mais.\n",
            "\n",
            "## Forem de Vibe Coding\n",
            "\n",
            "Seguir\n",
            "\n",
            "Discutindo desenvolvimento de software de IA e mostrando o que estamos construindo.\n",
            "\n",
            "## Comunidade DUMB DEV\n",
            "\n",
            "Seguir\n",
            "\n",
            "Memes e shitposting sobre desenvolvimento de software\n",
            "\n",
            "## Popcorn Movies and TV\n",
            "\n",
            "Seguir\n",
            "\n",
            "Entusiasmo, cr√≠tica e tudo mais sobre filmes e TV.\n",
            "\n",
            "## Comunidade de Design\n",
            "\n",
            "Seguir\n",
            "\n",
            "Web design, design gr√°fico e tudo mais\n",
            "\n",
            "## Forem de Seguran√ßa\n",
            "\n",
            "Seguir\n",
            "\n",
            "Seu centro para tudo sobre seguran√ßa. De hacking √©tico e CTFs a GRC e desenvolvimento de carreira, para iniciantes e profissionais\n",
            "\n",
            "## Forem de Golfe\n",
            "\n",
            "Seguir\n",
            "\n",
            "Uma comunidade de jogadores e entusiastas de golfe\n",
            "\n",
            "## Forem de Cripto\n",
            "\n",
            "Seguir\n",
            "\n",
            "Uma comunidade colaborativa para tudo relacionado a Cripto ‚Äî de Bitcoin a desenvolvimento de protocolos e DeFi a NFTs e an√°lise de mercado.\n",
            "\n",
            "## Parentalidade\n",
            "\n",
            "Seguir\n",
            "\n",
            "Um lugar para os pais compartilharem as alegrias, desafios e sabedoria que v√™m de criar filhos. Estamos aqui para eles e uns para os outros.\n",
            "\n",
            "## Forem Core\n",
            "\n",
            "Seguir\n",
            "\n",
            "Discutindo o projeto de software de c√≥digo aberto do core forem ‚Äî recursos, bugs, desempenho, auto-hospedagem.\n",
            "\n",
            "## Forem de Criadores\n",
            "\n",
            "Seguir\n",
            "\n",
            "Uma comunidade para criadores, entusiastas e profissionais discutirem Arduino, Raspberry Pi, impress√£o 3D e muito mais.\n",
            "\n",
            "## Forem HMPL.js\n",
            "\n",
            "Seguir\n",
            "\n",
            "Para desenvolvedores que usam HMPL.js para construir aplicativos web r√°pidos e leves. Um espa√ßo para compartilhar projetos, fazer perguntas e discutir templating impulsionado por servidor\n",
            "\n",
            "Dropdown menu\n",
            "Dropdown menu\n",
            "Pular para o conte√∫do\n",
            "Menu de navega√ß√£o\n",
            "Pesquisar\n",
            "Desenvolvido por Algolia\n",
            "Pesquisar\n",
            "Entrar\n",
            "Criar conta\n",
            "Comunidade DEV\n",
            "Fechar\n",
            "Adicionar rea√ß√£o\n",
            "Curtir\n",
            "Unic√≥rnio\n",
            "Cabe√ßa Explodindo\n",
            "M√£os Levantadas\n",
            "Fogo\n",
            "Ir para os Coment√°rios\n",
            "Salvar\n",
            "Impulsionar\n",
            "Mais...\n",
            "Copiar link\n",
            "Copiar link\n",
            "Copiado para a √Årea de Transfer√™ncia\n",
            "Compartilhar no X\n",
            "Compartilhar no LinkedIn\n",
            "Compartilhar no Facebook\n",
            "Compartilhar no Mastodon\n",
            "Denunciar Abuso\n",
            "\n",
            "## Kenichiro Nakamura\n",
            "\n",
            "Postado em\n",
            "12 de outubro de 2023\n",
            "\n",
            "## Azure Open AI em VNet\n",
            "\n",
            "# azure\n",
            "# openai\n",
            "# seguran√ßa\n",
            "\n",
            "Os modelos GPT s√£o hospedados em v√°rios fornecedores de servi√ßo no momento, e a Microsoft Azure √© um deles.\n",
            "Embora os modelos sejam os mesmos, existem muitas diferen√ßas, incluindo:\n",
            "\n",
            "*   custo\n",
            "*   funcionalidades\n",
            "*   tipo de modelos e vers√µes\n",
            "*   localiza√ß√£o geogr√°fica\n",
            "*   seguran√ßa\n",
            "*   suporte\n",
            "*   etc.\n",
            "\n",
            "Um dos aspectos mais importantes quando o utilizamos em um Ambiente Corporativo √©, claro, a seguran√ßa.\n",
            "Ao usar os recursos de seguran√ßa de rede do Azure com o Azure Open AI, os clientes podem consumir o servi√ßo Open AI de e dentro da VNet, portanto, nenhuma informa√ß√£o flui em p√∫blico.\n",
            "\n",
            "### Exemplo de Implanta√ß√£o\n",
            "\n",
            "O reposit√≥rio de Amostras do Azure fornece arquivos Bicep de exemplo para implantar o Azure Open AI em um ambiente VNet.\n",
            "\n",
            "GitHub: [openai-enterprise-iac](https://github.com/Azure-Samples/openai-enterprise-iac)\n",
            "\n",
            "As principais funcionalidades que o Bicep utiliza s√£o:\n",
            "\n",
            "*   VNet\n",
            "*   Integra√ß√£o de VNet para Web App\n",
            "*   Private Endpoint para Azure Open AI\n",
            "*   Private Endpoint para Cognitive Search\n",
            "*   Private DNS Zone\n",
            "\n",
            "Ao usar esses recursos, todo o tr√°fego de sa√≠da do Web App √© roteado apenas dentro da VNet e todos os nomes s√£o resolvidos para endere√ßos IP privados. O Open AI e o Cognitive Search desativam o endere√ßo IP p√∫blico, assim n√£o h√° mais um endpoint de interface p√∫blica dispon√≠vel.\n",
            "\n",
            "### Implantar\n",
            "\n",
            "O arquivo Bicep implantar√° os seguintes Recursos do Azure.\n",
            "\n",
            "Vamos implantar e confirmar como funciona. Criei um grupo de recursos na regi√£o Leste dos EUA para meu pr√≥prio teste.\n",
            "\n",
            "```bash\n",
            "git clone https://github.com/Azure-Samples/openai-enterprise-iac\n",
            "cd openai-enterprise-iac\n",
            "az group create -n openaitest -l eastus\n",
            "az deployment group create -g openaitest -f .\\infra\\main.bicep\n",
            "```\n",
            "Entrar no modo de tela cheia\n",
            "Sair do modo de tela cheia\n",
            "\n",
            "Assim que executo o comando acima, vejo que a implanta√ß√£o foi iniciada.\n",
            "\n",
            "Aguarde at√© que a implanta√ß√£o seja conclu√≠da.\n",
            "\n",
            "### Testar\n",
            "\n",
            "Vamos ver se a implanta√ß√£o foi bem-sucedida.\n",
            "\n",
            "#### Azure Open AI\n",
            "\n",
            "Vamos tentar o acesso p√∫blico primeiro.\n",
            "\n",
            "Consegui criar uma implanta√ß√£o sem nenhum problema. Mas quando tento pelo Chat playground no meu Portal do Azure, vejo o seguinte erro.\n",
            "\n",
            "E o acesso via Web API?\n",
            "\n",
            "De uma ferramenta avan√ßada do Servi√ßo de Aplicativo, fa√ßo login na sess√£o Bash e, primeiro, fa√ßo ping na URL do servi√ßo.\n",
            "\n",
            "Vejo que o endere√ßo IP privado atribu√≠do ao Private Endpoint √© retornado.\n",
            "\n",
            "Em seguida, uso o comando curl para enviar uma solicita√ß√£o ao endpoint.\n",
            "\n",
            "Coment√°rios principais\n",
            "(0)\n",
            "Assinar\n",
            "Pessoal\n",
            "Usu√°rio Confi√°vel\n",
            "Criar modelo\n",
            "Modelos permitem que voc√™ responda rapidamente a FAQs ou armazene trechos para reutiliza√ß√£o.\n",
            "Enviar\n",
            "Pr√©-visualizar\n",
            "Descartar\n",
            "C√≥digo de Conduta\n",
            "‚Ä¢\n",
            "Denunciar abuso\n",
            "Tem certeza de que deseja ocultar este coment√°rio? Ele ficar√° oculto em sua postagem, mas ainda ser√° vis√≠vel atrav√©s do\n",
            "permalink do coment√°rio.\n",
            "Ocultar tamb√©m os coment√°rios filhos\n",
            "Confirmar\n",
            "Para outras a√ß√µes, voc√™ pode considerar bloquear esta pessoa e/ou\n",
            "denunciar abuso\n",
            "Kenichiro Nakamura\n",
            "Seguir\n",
            "Membro desde\n",
            "3 de fevereiro de 2018\n",
            "Mais de\n",
            "Kenichiro Nakamura\n",
            "Azure ML Prompt flow: Use a seguran√ßa de conte√∫do antes de enviar uma solicita√ß√£o para LLM\n",
            "# azure\n",
            "# promptflow\n",
            "# contentsafety\n",
            "N√£o perca tempo para escrever README, use readme-ai em vez disso\n",
            "# ai\n",
            "# readme\n",
            "# openai\n",
            "C#: Azure Open AI e Chamada de Fun√ß√£o\n",
            "# azure\n",
            "# openai\n",
            "# functioncalling\n",
            "üíé Patrocinadores Diamante da DEV\n",
            "Obrigado aos nossos Patrocinadores Diamante por apoiar a Comunidade DEV\n",
            "Google AI √© o Parceiro Oficial de Modelo e Plataforma de IA da DEV\n",
            "Neon √© o parceiro oficial de banco de dados da DEV\n",
            "Algolia √© o parceiro oficial de busca da DEV\n",
            "Comunidade DEV\n",
            "‚Äî Um espa√ßo para discutir e manter-se atualizado sobre desenvolvimento de software e gerenciar sua carreira em software\n",
            "In√≠cio\n",
            "Sobre\n",
            "Contato\n",
            "C√≥digo de Conduta\n",
            "Pol√≠tica de Privacidade\n",
            "Termos de Uso\n",
            "Constru√≠do sobre\n",
            "Forem\n",
            "‚Äî o software\n",
            "de c√≥digo aberto\n",
            "que impulsiona\n",
            "DEV\n",
            "e outras comunidades inclusivas.\n",
            "Feito com amor e\n",
            "Ruby on Rails . Comunidade DEV\n",
            "¬©\n",
            "2016 - 2026.\n",
            "Somos um lugar onde programadores compartilham, mant√™m-se atualizados e desenvolvem suas carreiras.\n",
            "Entrar\n",
            "Criar conta\n",
            "```\n"
          ]
        }
      ]
    }
  ]
}